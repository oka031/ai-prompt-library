# データクレンジング・前処理プロンプト

## 基本情報
- 目的: 生データを分析に適した形に整理し、効果的な前処理手順を提案する
- 対象モデル: Claude, GPT-4
- 難易度: 中級
- 作成日: 2025-03-29

## プロンプト本文
あなたはデータサイエンスのエキスパートで、特にデータの前処理とクレンジングに精通しています。私のデータセットを分析し、分析に最適な状態にするための具体的な前処理手順を提案してください。

【データセットの概要】
- データの種類: [例: CSVファイル、データベースエクスポート、ログデータなど]
- 行数と列数の概算: [例: 約10,000行 x 15列]
- 目的: [例: 機械学習モデル構築、ダッシュボード作成、統計分析など]
- 利用予定のツール: [例: Python/pandas, SQL, Excelなど]

【データサンプル】
[ここにデータの最初の5-10行程度をコピー&ペースト]

【現在確認できる問題点】
[気づいている問題点があれば記載: 欠損値、異常値、形式不一致など]

以下の形式で前処理手順を提案してください:

1. データ品質の評価（現状分析）
    - 主な問題点のリスト（欠損値、異常値、重複、形式不一致など）
    - 問題の深刻度と影響の評価
2. ステップバイステップのクレンジング手順
    - 各ステップの具体的なコード例またはSQL文（利用予定ツールに合わせて）
    - 処理の目的と期待される効果の説明
    - 処理の順序と依存関係の明確化
3. データ変換と特徴エンジニアリングの提案
    - 分析目的に沿った変数変換
    - 新たに作成すべき派生変数
    - 不要と思われる変数の取り扱い
4. 効率化とベストプラクティス
    - 処理パイプラインの効率化提案
    - 将来のデータ更新への対応方法
    - 注意すべき潜在的な問題点

特に重要なのは、単に一般的な前処理手順ではなく、このデータセット固有の特性と分析目的に最適化された具体的な手順です。また、各提案には理由を付け、なぜその処理が必要なのかを説明してください。

## 使用例
- 機械学習プロジェクトの前処理パイプライン構築
- 分析用データセットの品質向上
- データウェアハウスへの取り込み前の処理設計
- 自動化されたETLプロセスの構築

## カスタマイズポイント
- データの種類: 具体的なデータフォーマットやソース
- 行数と列数: データサイズに応じた処理方法の最適化
- 分析目的: 機械学習、可視化、統計分析など目的に合わせて調整
- 利用ツール: 使用するプログラミング言語やツールに合わせたコード例

## 期待される結果
データセット固有の問題に対処した具体的な前処理手順と、それを実装するためのコード例。単なるGeneric なアドバイスではなく、提供したデータサンプルに基づいた実用的な手順。データの品質向上と分析準備を効率的に行うための完全なガイドが得られる。
